{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TME ROBOTIQUE ET APPRENTISSAGE</font>\n",
    "# <font color='red'>Optimisation multi-objectif</font>\n",
    "\n",
    "<font color=\"red\">Version étudiant 2021-2022</font>\n",
    "\n",
    "*mise à jour: 28/03/2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook peut être exécuté dans [Google Colab](colab.research.google.com/)\n",
    "\n",
    "Pour faciliter la lisibilité du notebook, le code donné, à écrire ou à compléter est dans les cellules en annexe, à la fin du notebook. Les cellules de réponses ne doivent contenir que les quelques instructions permettant d'afficher les résultats (éventuellement des appels permettant de les générer) et les commentaires d'analyse associés.\n",
    "\n",
    "Vous devez déposer votre travail sur Moodle:\n",
    "* déposer votre notebook, avec le nom de fichier *obligatoirement* au format suivant: **RA_NOM1_NOM2.ipynb**\n",
    "* toutes les cellules exécutées\n",
    "* des graphes et un commentaire sur les résultats obtenus\n",
    "* affichage limité au nécessaire pour assurer la lisibilité du notebook (pas d'affichage de debug ni de centaines de graphes !)\n",
    "\n",
    "*Le sujet est à faire en binome.*\n",
    "\n",
    "# COMPLETEZ LES CHAMPS CI-DESSOUS AVEC NOM/PRENOM/CARTE_ETU:\n",
    "\n",
    "* Étudiant 1: **_Nom_ _Prénom_ _noCarteEtudiant_**\n",
    "* Étudiant 2: **_Nom_ _Prénom_ _noCarteEtudiant_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Dans ce TME, vous allez mettre en oeuvre des algorithmes évolutionnistes, notamment multi-objectifs pour faire de l'apprentissage. Pour cela, différentes fonctions vous sont fournies afin de tracer les individus générés à chaque génération ou de comparer les résultats entre eux. Vous testerez également Gym, un environnement utilisé en apprentissage par renforcement pour normaliser les expériences d'apprentissage sur des robots (virtuels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dépendances\n",
    "\n",
    "Vous aurez besoin de la bibliothèque DEAP (https://deap.readthedocs.io/en/master/) et d'OpenAI Gym (https://gym.openai.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deap\n",
    "!pip install gym\n",
    "!pip install scoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à exécuter pour pouvoir tracer les courbes demandées\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pour que les figures apparaissent directement dans le notebook\n",
    "%matplotlib inline \n",
    "\n",
    "import random\n",
    "# ne pas oublier d'initialiser la graine aléatoire...\n",
    "random.seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Scoop\n",
    "\n",
    "DEAP est compatible avec une bibliothèque de parallisation appelée SCOOP. Elle permet d'évaluer plusieurs solutions en tirant partie des architectures multi-coeur. Cette bibliothèque ne peut malheureusement pas être utilisée dans un notebook. Pour l'utiliser, il faut appeler le programme python en chargeant le module scoop. Depuis une cellule du notebook, cela se fait comme cela:\n",
    "<pre>!python3 -m scoop programme.py</pre>\n",
    "\n",
    "Pour permettre son utilisation, les cellules de code en annexe disposent d'une commande \"magique\" pour à la fois les exécuter et les écrire dans un fichier. Vous pouvez donc les importer ou lancer les programmes soit depuis le notebook, soit depuis un terminal, soit encore depuis le notebook avec un appel de type:\n",
    "<pre>!python3 programme.py</pre>\n",
    "\n",
    "**Remarque:** la parallélisation que permet scoop n'est intéressante que si les évaluations sont suffisamment longues. Dans le TME, ce sera intéressant pour les expériences avec Gym, si les temps d'évaluation sont suffisamment longs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prise en main de DEAP\n",
    "\n",
    "Dans la suite du TME, vous serez invités à utiliser DEAP, cf https://deap.readthedocs.io/en/master/index.html.\n",
    "\n",
    "Comme cela a déjà été vu, DEAP est une bibliothèque de prototypage rapide d'algorithmes évolutionnistes. Elle permet de travailler à plusieurs niveaux, depuis l'implémentation complète de l'algorithme à partir de briques de base jusqu'à l'utilisation boite noire d'un algorithme entièrement implémenté et en passant par des approches intermédiaires, dans lesquelles des modules sont réutilisés, par exemple pour la sélection, les mutations ou les croisements.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sélection par tournoi\n",
    "\n",
    "Complétez le code en annexe pour implémenter un algorithme évolutionniste avec une sélection par tournoi qui choisira les parents sur la base de tournois à 3 individus choisis aléatoirement avec une population de taille donnée (les valeurs possibles sont indiquées ci-dessous).\n",
    "\n",
    "Détails de l'algorithme à implémenter:\n",
    "- croisement de type SBX (Simulated Binary Crossover), eta=15\n",
    "- mutation de type polynomiale bornée, eta=15.0 et indpb=1/IND_SIZE (IND_SIZE étant la taille d'un génome)\n",
    "\n",
    "Voir https://deap.readthedocs.io/en/master/api/tools.html pour les différents opérateurs défini dans DEAP et la documentation associée. Vous utiliserez les fonctions de la toolbox DEAP pour faciliter votre implémentation et vous pourrez vous inspirer des exemples fournis.\n",
    "\n",
    "Les paramètres seront initialisés entre -5 et 5 (vous pourrez utiliser random.uniform pour l'initialisation).\n",
    "\n",
    "**Remarque:** la méthode `register` de la toolbox permet d'enregistrer une fonction dans cette toolbox sous un nom donné en premier argument. Le deuxième argument est le nom de la fonction. Les arguments suivants sont optionnels et seront transmis automatiquement à la fonction lorsqu'elle sera appelée (en plus des arguments qui seront éventuellement ajoutés lors de l'appel, par exemple l'individu à muter dans le cas d'une méthode de mutation). Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import tools,base\n",
    "\n",
    "def mon_test(a, b):\n",
    "    print(\"a=\"+str(a)+\" b=\"+str(b))\n",
    "toolbox = base.Toolbox() \n",
    "toolbox.register(\"test\", mon_test, a=3)\n",
    "toolbox.test(b=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les algorithmes évolutionnistes ont une part stochastique et ne donnent donc pas toujours le même résultat. Vous tracerez donc l'évolution de la meilleure fitness pour 10 runs indépendants. Plutôt que de tracer les 10 courbes, vous tracerez la médiane des maxima et un intervalle représentant le 1er et le 3eme quartile. Vous procéderez pour cela de la façon suivante:\n",
    "\n",
    "\n",
    "    plt.plot(gen,median_max, label=\"Mediane des max\")\n",
    "    plt.fill_between(gen, fit_25, fit_75, alpha=0.25, linewidth=0)\n",
    "\n",
    "gen étant une liste de générations, median_max la liste des médianes des maxima et fit_25 et fit_75 les 1er et 3eme quartiles. Vous pourrez les déterminer avec la fonction quantile de numpy: quantile(points, 0.25) et quantile(points, 0.75), avec points une liste qui contient les fitness des différents runs à une génération donnée (il faut donc faire une boucle et appeler ces fonctions pour chaque génération).\n",
    "\n",
    "Vous testerez votre algorithme sur la fonction de Ackley. Elle est disponible dans DEAP et peut être appelée dans n'importe quelle dimension. Vous pourrez faire vos tests avec la dimension IND_SIZE=10, par exemple. \n",
    "\n",
    "Complétez le code en annexe et tracez les courbes pour des populations de taille croissante: [5, 10, 100, 200]. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter pour appeler votre algorithme évolutionniste sur les différentes tailles de population et tracer l'évolution de la fitness moyenne\n",
    "# Ne pas utiliser SCOOP dans cette question, vous pouvez directement faire appel à votre fonction implémentant l'algorithme évolutionniste\n",
    "\n",
    "# <INIT_DEAP>\n",
    "# Code d'initialisation du \"créateur\" de DEAP, partie à mettre dans le programme principal\n",
    "# NE PAS MODIFIER\n",
    "weights=(-1.0,)\n",
    "from deap import creator, base\n",
    "set_creator(creator)\n",
    "\n",
    "if (hasattr(creator, \"MaFitness\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.MaFitness\n",
    "creator.create(\"MaFitness\", base.Fitness, weights=(weights))\n",
    "\n",
    "if (hasattr(creator, \"Individual\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.Individual\n",
    "creator.create(\"Individual\", list, fitness=creator.MaFitness)\n",
    "# </INIT_DEAP>    \n",
    "\n",
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire:\n",
    "<ANSWER>\n",
    "\n",
    "</ANSWER>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sélection élitiste\n",
    "\n",
    "Même question mais avec une séleciton de type élitiste: à chaque génération, création de pop_size nouveaux individus (par copie de la population courante, puis mutation de chaque individu avec une probabilité de MUTPB et croisement avec une probabilité de CXPB, vous pourrez utiliser l'algorithme varAnd: https://deap.readthedocs.io/en/master/api/algo.html?highlight=varand#deap.algorithms.varAnd) et sélection des pop_size meilleurs parmi les enfants ainsi générés et leurs parents (Attention: l'appel à la fonction de sélection ne se fera pas au même endroit que pour l'algorithme précédent).\n",
    "\n",
    "Complétez le code en annexe et tracez les courbes pour des populations de taille croissante: [5, 10, 100, 200]. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter pour appeler votre algorithme évolutionniste sur les différentes tailles de population et tracer l'évolution de la fitness moyenne\n",
    "# Ne pas utiliser SCOOP dans cette question, vous pouvez directement faire appel à votre fonction implémentant l'algorithme évolutionniste\n",
    "\n",
    "\n",
    "# <INIT_DEAP>\n",
    "# Code d'initialisation du \"créateur\" de DEAP, partie à mettre dans le programme principal\n",
    "# NE PAS MODIFIER\n",
    "weights=(-1.0,)\n",
    "\n",
    "from deap import creator, base\n",
    "set_creator(creator)\n",
    "\n",
    "if (hasattr(creator, \"MaFitness\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.MaFitness\n",
    "creator.create(\"MaFitness\", base.Fitness, weights=(weights))\n",
    "\n",
    "if (hasattr(creator, \"Individual\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.Individual\n",
    "creator.create(\"Individual\", list, fitness=creator.MaFitness)\n",
    "# </INIT_DEAP>  \n",
    "    \n",
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire:\n",
    "<ANSWER>\n",
    "\n",
    "</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque:** les performances relatives des stratégies de sélection élitiste ou par tournoi dependent des caractéristiques de la fonction à optimiser, ne pas tirer de conclusion trop générales de vos observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implémentation de NSGA-II\n",
    "\n",
    "Implémentez maintenant NSGA-II en vous appuyant sur les fonctions fournies dans DEAP (annexe question 2 à compléter). Vous testerez NSGA-II sur un benchmark multi-objectif fourni dans DEAP, par exemple, la fonction de Fonseca et Fleming.\n",
    "\n",
    "Utilisez l'hypervolume pour caractériser la performance et tracer les courbes avec l'hypervolume (moyenne et 1er-3eme quartiles).\n",
    "\n",
    "Comme précédemment, tracez l'évolution de l'hypervolume (mediane des max et 1er et 3eme quartiles) pour des populations de taille [5, 10, 100, 200]. \n",
    "\n",
    "Que remarquez-vous ?\n",
    "\n",
    "Dans le cas de la fonction de Fonseca, vous pourrez utiliser (1,1) comme point de référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exemple d'utilisation du code de calcul de l'hypervolume. L'hypothèse est celle d'une minimisation.\")\n",
    "print(\"Il faut donner un point de référence correspondant, par exemple, aux valeurs maximales pour les objectifs.\")\n",
    "from deap.tools._hypervolume import hv\n",
    "print(\"Hypervolume: %f\"%(hv.hypervolume([np.array([1,0]), np.array([1,1]), np.array([0,1])], np.array([2,2]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter pour appeler votre algorithme évolutionniste sur les différentes tailles de population et tracer l'évolution de la fitness moyenne\n",
    "\n",
    "# <INIT_DEAP>\n",
    "# Code d'initialisation du \"créateur\" de DEAP, partie à mettre dans le programme principal\n",
    "# NE PAS MODIFIER\n",
    "weights=(-1.0,-1.0)\n",
    "\n",
    "from deap import creator, base\n",
    "set_creator(creator)\n",
    "\n",
    "if (hasattr(creator, \"MaFitness\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.MaFitness\n",
    "creator.create(\"MaFitness\", base.Fitness, weights=(weights))\n",
    "\n",
    "if (hasattr(creator, \"Individual\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.Individual\n",
    "creator.create(\"Individual\", list, fitness=creator.MaFitness)\n",
    "# </INIT_DEAP>  \n",
    "    \n",
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire:\n",
    "<ANSWER>\n",
    "\n",
    "</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apprentissage de politiques avec gym\n",
    "\n",
    "L'objectif de cette question est d'utiliser l'algorithme évolutionniste pour apprendre des politiques. Comme lors du TME précédent, vous utiliserez pour cela un problème très simple: le pendule inversé. Il s'agit de contrôler un pendule fixé sur un chariot et capable de tourner. Le chariot peut se déplacer horizontalement. Les mouvements horizontaux du pendule font osciller le pendule et l'objectif est de le maintenir à la verticale.\n",
    "\n",
    "Les paramètres soumis à l'optimisation par algorithme évolutionniste seront les paramètres de la politique qui contrôle le pendule. Vous pourrez donc réutiliser telles quelles les implémentations que vous venez de réaliser en remplaçant simplement la fonction d'évaluation par une fonction qui calcule la fitness associée à un jeu de paramètre de politiques donné. Cette évaluation sera faite avec OpenAI-Gym. \n",
    "\n",
    "OpenAI-gym est un framework permettant d'implémenter des expériences d'apprentissage par renforcement. Il propose une interface simple et unifiée et inclut de nombreux environnements utilisés pour tester des algorithmes d'apprentissage par renforcement. Comme lors du TME précédent, vous utiliserez cet environnement et son module CartPole-v1 pour apprendre à contrôler le pendule (voir https://gym.openai.com/envs/CartPole-v1/). \n",
    "\n",
    "Les annexes contiennent:\n",
    "- `nn.py`: le code associé à une politique représentée sous forme de réseaux de neurones: **NE PAS MODIFIER**\n",
    "- `cartpole.py`: le squelette de code de la fonction d'évaluation s'appuyant sur Gym: **COMPLÉTER LA CELLULE**\n",
    "- `cartpole_ea.py`: le squelette de code d'appel à l'algorithme évolutionniste: **COMPLÉTER LA CELLULE**\n",
    "\n",
    "\n",
    "Vous tracerez dans le notebook l'évolution des fitness comme dans la question précédente. Les calculs étant plus longs, vous pouvez vous limiter à une taille de population et un seul run. Faites en fonction de vos capacités de calcul et, le cas échéant, indiquez en commentaire ce que vous vous attendriez à observer avec une puissance de calcul supérieure. \n",
    "\n",
    "Vous choisirez la taille de population et le nombre de d'expériences à réaliser en fonction de la puissance de calcul disponible (des tailles de 100 ou 200 sont souhaitables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python3 cartpole_ea.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python3 -m scoop cartpole_ea.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: L'évaluation du pendule commence à une position aléatoire. Affichez plusieurs fois de suite la fitness obtenue en visualisant un même individu. Vous devriez observez que la fitness obtenue n'est pas toujours la même. C'est une illustration du problème de la généralisation. Pendant l'apprentissage, une politique n'a été testée que dans une condition particulière. Si vous changer un peu les conditions, vous n'avez pas de garantie sur ce qu'il va se passer... Pour limiter ce problème, une stratégie simple consiste à calculer la fitness non pas sur une seule évaluation, mais sur plusieurs et à prendre la moyenne (ou la somme) de ces différentes évaluations. Cela devrait réduire la variabilité observée. Si la puissance de calcul dont vous disposez le permet, vous pouvez modifier ainsi votre fontion d'évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apprentissage direct dans l'espace des politiques, version multi-objectif\n",
    "\n",
    "Le pendule inversé est en fait un problème multi-objectif dans lequel le pendule doit être maintenu à la verticale, le chariot étant centré dans une zone donnée. \n",
    "\n",
    "### 5.1 Carpole & NSGA-2\n",
    "\n",
    "Compléter la cellule de la question 5 pour minimiser l'erreur en x et en theta avec NSGA-2. Comme précédemment, vous tracerez l'évolution de l'hypervolume (prendre un point de référence à [1000, 1000]). \n",
    "\n",
    "Vous choisirez la taille de population et le nombre de d'expériences à réaliser en fonction de la puissance de calcul disponible (des tailles de 100 ou 200 sont souhaitables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python3 cartpole_nsga2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python3 -m scoop cartpole_nsga2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Comparaisons entre mono- et multi-objectif\n",
    "\n",
    "Tracez sur une même figure les valeurs finales atteintes (erreur en x et erreur en theta) pour des expériences en mono-objectif et en multi-objectif. \n",
    "\n",
    "Pour les expériences en mono-objectif, vous tracerez un point par expérience.\n",
    "\n",
    "Pour les expériences en multi-objectif, vous tracerez, pour chaque expérience, l'approximation du front de Pareto obtenue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def run_and_save(line, cell):\n",
    "    print(\"Run and save python code block to file: \"+line)\n",
    "    with open(line, 'wt') as fd:\n",
    "        fd.write(cell)\n",
    "    code = compile(cell, line, 'exec')\n",
    "    exec(code, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code de la question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save ea_tournament.py\n",
    "\n",
    "\n",
    "# <INIT_DEAP>\n",
    "# Code d'initialisation du \"créateur\" de DEAP, partie à mettre dans un module\n",
    "# NE PAS MODIFIER\n",
    "creator = None\n",
    "def set_creator(cr):\n",
    "    global creator\n",
    "    creator = cr\n",
    "\n",
    "from deap import base, tools, algorithms\n",
    "# </INIT_DEAP>\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def ea_tournament(n, nbgen, evaluate, IND_SIZE, MIN_V=-5, MAX_V=5, CXPB=0.5, MUTPB=0.2, weights=(1,)):\n",
    "    \"\"\"Algorithme evolutionniste avec sélection par tournoi\n",
    "\n",
    "    Algorithme evolutionniste avec sélection par tournoi (tournoi sur 3 individus). \n",
    "    :param n: taille de la population\n",
    "    :param nbgen: nombre de generation \n",
    "    :param evaluate: la fonction d'évaluation\n",
    "    :param IND_SIZE: la taille d'un individu\n",
    "    :param MIN_V: la valeur minimale d'un paramètre du génome\n",
    "    :param MAX_V: la valeur maximale d'un paramètre du génome\n",
    "    :param CXPB: la probabilité de croisement\n",
    "    :param MUTPB: la probabilité de mutation\n",
    "    :param weights: les poids à utiliser pour la somme pondérée en cas de problème multi-objectif (pour en faire une somme pondérée), ATTENTION, c'est différent du paramètre weights de DEAP qui détermine si c'est une maximisation ou une minimisation \n",
    "    \"\"\"\n",
    "\n",
    "    #print(\"EA Tournament: n=%d nbgen=%d, IND_SIZE=%d, MIN_V=%f, MAX_V=%f, CXPB=%f, MUTPB=%f\"%(n,nbgen,IND_SIZE, MIN_V, MAX_V, CXPB, MUTPB)+\" weights=\"+str(weights))\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    toolbox.register(\"map\",futures.map)\n",
    "    \n",
    "    \n",
    "    # à compléter pour sélectionner les différents opérateurs (dont mutation, croisement, sélection) avec des toolbox.register\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "\n",
    "\n",
    "    # Les statistiques permettant de récupérer les résultats\n",
    "    stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # La structure qui permet de stocker les statistiques\n",
    "    logbook = tools.Logbook()\n",
    "\n",
    "\n",
    "    # La structure permettant de récupérer le meilleur individu\n",
    "    hof = tools.HallOfFame(1) \n",
    "\n",
    "\n",
    "    population = toolbox.population(n=n)\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    fitnesses = list(toolbox.map(toolbox.evaluate, population))\n",
    "    if(len(weights)!=len(fitnesses[0])):\n",
    "        print(\"ERROR: the weights and the fitness should have the same size ! weights=\"+str(weights)+\" fitness=\"+str(fitnesses[0]))\n",
    "        return\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        #print(\"Fit: \"+str(fit)) \n",
    "        prod=[weights[i]*fit[i] for i in range(len(fit))]\n",
    "        ind.fitness.values = (sum(prod),) # somme pondérée si fonction à optimiser multi-objectif\n",
    "        ind.lfit=fit # sauvegarde des valeurs des objectifs\n",
    "    hof.update(population)\n",
    "    stat = stats.compile(population)\n",
    "    logbook.record(gen=0,best=hof[0].lfit,**stat) \n",
    "    # le champ \"best\" pourra être utilisé pour faciliter les comparaisons avec NSGA-2 dans l'expérience multi-objectif de contrôle du pendule (question 5.2)\n",
    "    \n",
    "    \n",
    "    for g in range(1,nbgen):\n",
    "\n",
    "        # Pour voir l'avancement\n",
    "        if (g%10==0):\n",
    "            print(\"+\",end=\"\", flush=True)\n",
    "        else:\n",
    "            print(\".\",end=\"\", flush=True)\n",
    "\n",
    "\n",
    "        ## à compléter en n'oubliant pas de mettre à jour les statistiques, le logbook et le hall-of-fame comme cela a été fait pour la génération 0\n",
    "\n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "        \n",
    "    return population, hof, logbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de la question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save ea_elitist.py\n",
    "\n",
    "import numpy as np\n",
    "from deap import base, creator, benchmarks\n",
    "import random\n",
    "from deap import tools\n",
    "from scoop import futures\n",
    "\n",
    "# <INIT_DEAP>\n",
    "# Code d'initialisation du \"créateur\" de DEAP, partie à mettre dans un module\n",
    "# NE PAS MODIFIER\n",
    "creator = None\n",
    "def set_creator(cr):\n",
    "    global creator\n",
    "    creator = cr\n",
    "\n",
    "from deap import base, tools, algorithms\n",
    "# </INIT_DEAP>\n",
    "\n",
    "def ea_elitist(n, nbgen, evaluate, IND_SIZE, MIN_V=-5, MAX_V=5, CXPB=0.5, MUTPB=0.2, weights=(1,)):\n",
    "    \"\"\"Algorithme evolutionniste avec sélection élitiste\n",
    "\n",
    "    Algorithme evolutionniste avec sélection élitiste. \n",
    "    :param n: taille de la population\n",
    "    :param nbgen: nombre de generation \n",
    "    :param evaluate: la fonction d'évaluation\n",
    "    :param IND_SIZE: la taille d'un individu\n",
    "    :param MIN_V: la valeur minimale d'un paramètre du génome\n",
    "    :param MAX_V: la valeur maximale d'un paramètre du génome\n",
    "    :param CXPB: la probabilité de croisement\n",
    "    :param MUTPB: la probabilité de mutation\n",
    "    :param weights: les poids à utiliser pour la somme pondérée en cas de problème multi-objectif (pour en faire une somme pondérée), ATTENTION, c'est différent du paramètre weights de DEAP qui détermine si c'est une maximisation ou une minimisation \n",
    "    \"\"\"\n",
    "\n",
    "    #print(\"EA Elitist: n=%d nbgen=%d, IND_SIZE=%d, MIN_V=%f, MAX_V=%f, CXPB=%f, MUTPB=%f\"%(n,nbgen,IND_SIZE, MIN_V, MAX_V, CXPB, MUTPB)+\" weights=\"+str(weights))\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    toolbox.register(\"map\",futures.map)\n",
    "    \n",
    "    # à compléter pour sélectionner les opérateurs de mutation, croisement, sélection avec des toolbox.register(...)\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "\n",
    "\n",
    "    # Les statistiques permettant de récupérer les résultats\n",
    "    stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # La structure qui permet de stocker les statistiques\n",
    "    logbook = tools.Logbook()\n",
    "\n",
    "\n",
    "    # La structure permettant de récupérer le meilleur individu\n",
    "    hof = tools.HallOfFame(1) \n",
    "\n",
    "    population = toolbox.population(n=n)\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    fitnesses = list(toolbox.map(toolbox.evaluate, population))\n",
    "    if(len(weights)!=len(fitnesses[0])):\n",
    "        print(\"ERROR: the weights and the fitness should have the same size ! weights=\"+str(weights)+\" fitness=\"+str(fitnesses[0]))\n",
    "        return\n",
    "    spop=[]\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        #print(\"Fit: \"+str(fit)) \n",
    "        prod=[weights[i]*fit[i] for i in range(len(fit))]\n",
    "        ind.fitness.values = (sum(prod),)\n",
    "        ind.lfit=fit\n",
    "        spop.append(fit)\n",
    "    hof.update(population)\n",
    "    stat = stats.compile(population)\n",
    "    logbook.record(gen=0,pop=spop,best=hof[0].lfit,**stat)\n",
    "    # le champ \"best\" pourra être utilisé pour faciliter les comparaisons avec NSGA-2 dans l'expérience multi-objectif de contrôle du pendule (question 5.2)\n",
    "    \n",
    "    \n",
    "    for g in range(1,nbgen):\n",
    "\n",
    "        # Pour voir l'avancement\n",
    "        if (g%10==0):\n",
    "            print(\"+\",end=\"\", flush=True)\n",
    "        else:\n",
    "            print(\".\",end=\"\", flush=True)\n",
    "\n",
    "\n",
    "        ## à compléter en n'oubliant pas de mettre à jour les statistiques, le logbook et le hall-of-fame comme cela a été fait pour la génération 0\n",
    "\n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "        \n",
    "    return population, hof, logbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de la question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save nsga2.py\n",
    "import numpy as np\n",
    "\n",
    "# <INIT_DEAP>\n",
    "# Code d'initialisation du \"créateur\" de DEAP, partie à mettre dans un module\n",
    "# NE PAS MODIFIER\n",
    "creator = None\n",
    "def set_creator(cr):\n",
    "    global creator\n",
    "    creator = cr\n",
    "\n",
    "from deap import base, tools, algorithms\n",
    "# </INIT_DEAP>\n",
    "\n",
    "from deap.tools._hypervolume import hv\n",
    "\n",
    "from scoop import futures\n",
    "\n",
    "import random\n",
    "\n",
    "# ne pas oublier d'initialiser la grane aléatoire (le mieux étant de le faire dans le main))\n",
    "random.seed()\n",
    "\n",
    "def nsga2(n, nbgen, evaluate, IND_SIZE=5, ref_point=np.array([1,1]), MIN_V=-5, MAX_V=5, CXPB=0.5, MUTPB=0.2):\n",
    "    \"\"\"NSGA-2\n",
    "\n",
    "    NSGA-2\n",
    "    :param n: taille de la population\n",
    "    :param nbgen: nombre de generation \n",
    "    :param evaluate: la fonction d'évaluation\n",
    "    :param IND_SIZE: la taille d'un individu\n",
    "    :param ref_point: le point de référence pour le calcul de l'hypervolume\n",
    "    :param MIN_V: la valeur minimale d'un paramètre du génome\n",
    "    :param MAX_V: la valeur maximale d'un paramètre du génome\n",
    "    :param CXPB: la probabilité de croisement\n",
    "    :param MUTPB: la probabilité de mutation\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    paretofront = tools.ParetoFront()\n",
    "    \n",
    "    # Les statistiques permettant de récupérer les résultats\n",
    "    stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # La structure qui permet de stocker les statistiques\n",
    "    logbook = tools.Logbook()\n",
    "\n",
    "    # à compléter\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "    \n",
    "    toolbox.register(\"map\",futures.map)\n",
    "\n",
    "    population = toolbox.population(n=n)\n",
    "\n",
    "    \n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        #print(\"Fit: \"+str(fit)) \n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    paretofront.update(population)\n",
    "\n",
    "    pffit=[]\n",
    "    for i in paretofront:\n",
    "        pffit.append(i.fitness.values)\n",
    "\n",
    "    pointset=[np.array(ind.fitness.getValues()) for ind in paretofront]\n",
    "    shv=hv.hypervolume(pointset, ref_point)\n",
    "    stat = stats.compile(population)\n",
    "    logbook.record(gen=0, best=pffit,hypervolume=shv, **stat)\n",
    "    # Le champ best contient la fitness de chaque individu du front de pareto, cela permettra de faciliter les comparaisons pour la question 5.2.\n",
    "    \n",
    "    # Begin the generational process\n",
    "    for gen in range(1, nbgen):\n",
    "        if (gen%10==0):\n",
    "            print(\"+\",end=\"\", flush=True)\n",
    "        else:\n",
    "            print(\".\",end=\"\", flush=True)\n",
    "\n",
    "    \n",
    "        ## à compléter en n'oubliant pas de mettre à jour les statistiques, le logbook et le hall-of-fame comme cela a été fait pour la génération 0\n",
    "\n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "\n",
    "            \n",
    "    return population, paretofront, logbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de la question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save nn.py\n",
    "# NE PAS MODIFIER LE CONTENU DE CETTE CELLULE\n",
    "# Cette cellule contient le code de gestion d'une politique au travers d'un réseau de neurones de structure fixe. \n",
    "# Ce code n'a pas à être modifié ni complété, il suffit d'exécuter la cellule telle quelle.\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## Suppress TF info messages\n",
    "\n",
    "import os\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def gen_simplemlp(n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5):\n",
    "    n_neurons = [n_neurons_per_hidden]*n_hidden_layers if np.isscalar(n_neurons_per_hidden) else n_neurons_per_hidden\n",
    "    i = Input(shape=(n_in,))\n",
    "    x = i\n",
    "    for n in n_neurons:\n",
    "        x = Dense(n, activation='sigmoid')(x)\n",
    "    o = Dense(n_out, activation='tanh')(x)\n",
    "    m = Model(inputs=i, outputs=o)\n",
    "    return m\n",
    "    \n",
    "\n",
    "class SimpleNeuralControllerNumpy():\n",
    "    def __init__(self, n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5, params=None):\n",
    "        self.dim_in = n_in\n",
    "        self.dim_out = n_out\n",
    "        # if params is provided, we look for the number of hidden layers and neuron per layer into that parameter (a dicttionary)\n",
    "        if (not params==None):\n",
    "            if (\"n_hidden_layers\" in params.keys()):\n",
    "                n_hidden_layers=params[\"n_hidden_layers\"]\n",
    "            if (\"n_neurons_per_hidden\" in params.keys()):\n",
    "                n_neurons_per_hidden=params[\"n_neurons_per_hidden\"]\n",
    "        self.n_per_hidden = n_neurons_per_hidden\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.weights = None \n",
    "        self.n_weights = None\n",
    "        self.init_random_params()\n",
    "        self.out = np.zeros(n_out)\n",
    "        #print(\"Creating a simple mlp with %d inputs, %d outputs, %d hidden layers and %d neurons per layer\"%(n_in, n_out,n_hidden_layers, n_neurons_per_hidden))\n",
    "\n",
    "    \n",
    "    def init_random_params(self):\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            self.weights = [np.random.random((self.dim_in,self.n_per_hidden))] # In -> first hidden\n",
    "            self.bias = [np.random.random(self.n_per_hidden)] # In -> first hidden\n",
    "            for i in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                self.weights.append(np.random.random((self.n_per_hidden,self.n_per_hidden)))\n",
    "                self.bias.append(np.random.random(self.n_per_hidden))\n",
    "            self.weights.append(np.random.random((self.n_per_hidden,self.dim_out))) # -> last hidden -> out\n",
    "            self.bias.append(np.random.random(self.dim_out))\n",
    "        else:\n",
    "            self.weights = [np.random.random((self.dim_in,self.dim_out))] # Single-layer perceptron\n",
    "            self.bias = [np.random.random(self.dim_out)]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all network parameters as a single array\n",
    "        \"\"\"\n",
    "        flat_weights = np.hstack([arr.flatten() for arr in (self.weights+self.bias)])\n",
    "        return flat_weights\n",
    "\n",
    "    def set_parameters(self, flat_parameters):\n",
    "        \"\"\"\n",
    "        Set all network parameters from a single array\n",
    "        \"\"\"\n",
    "        i = 0 # index\n",
    "        to_set = []\n",
    "        self.weights = list()\n",
    "        self.bias = list()\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            # In -> first hidden\n",
    "            w0 = np.array(flat_parameters[i:(i+self.dim_in*self.n_per_hidden)])\n",
    "            self.weights.append(w0.reshape(self.dim_in,self.n_per_hidden))\n",
    "            i += self.dim_in*self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                w = np.array(flat_parameters[i:(i+self.n_per_hidden*self.n_per_hidden)])\n",
    "                self.weights.append(w.reshape((self.n_per_hidden,self.n_per_hidden)))\n",
    "                i += self.n_per_hidden*self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            wN = np.array(flat_parameters[i:(i+self.n_per_hidden*self.dim_out)])\n",
    "            self.weights.append(wN.reshape((self.n_per_hidden,self.dim_out)))\n",
    "            i += self.n_per_hidden*self.dim_out\n",
    "            # Samefor bias now\n",
    "            # In -> first hidden\n",
    "            b0 = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "            self.bias.append(b0)\n",
    "            i += self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                b = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "                self.bias.append(b)\n",
    "                i += self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            bN = np.array(flat_parameters[i:(i+self.dim_out)])\n",
    "            self.bias.append(bN)\n",
    "            i += self.dim_out\n",
    "        else:\n",
    "            n_w = self.dim_in*self.dim_out\n",
    "            w = np.array(flat_parameters[:n_w])\n",
    "            self.weights = [w.reshape((self.dim_in,self.dim_out))]\n",
    "            self.bias = [np.array(flat_parameters[n_w:])]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "    \n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        Propagage\n",
    "        \"\"\"\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            #Input\n",
    "            a = np.matmul(x,self.weights[0]) + self.bias[0]\n",
    "            y = sigmoid(a)\n",
    "            # hidden -> hidden\n",
    "            for i in range(1,self.n_hidden_layers-1):\n",
    "                a = np.matmul(y, self.weights[i]) + self.bias[i]\n",
    "                y = sigmoid(a)\n",
    "            # Out\n",
    "            a = np.matmul(y, self.weights[-1]) + self.bias[-1]\n",
    "            out = tanh(a)\n",
    "            return out\n",
    "        else: # Simple monolayer perceptron\n",
    "            return tanh(np.matmul(x,self.weights[0]) + self.bias[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save cartpole.py\n",
    "# A COMPLETER\n",
    "# Squelette du code de réponse à la question 4. \n",
    "\n",
    "import array\n",
    "import random\n",
    "\n",
    "import math\n",
    "import gym\n",
    "\n",
    "\n",
    "from nn import SimpleNeuralControllerNumpy\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Pour récupérer le nombre de paramètre. voir fixed_structure_nn_numpy pour la signification des paramètres. Le TME fonctionne avec ces paramètres là, mais vous pouvez explorer des valeurs différentes si vous le souhaitez.\n",
    "nn=SimpleNeuralControllerNumpy(4,1,2,5)\n",
    "IND_SIZE=len(nn.get_parameters())\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "\n",
    "def eval_nn(genotype, nbeval=1, render=False, nbstep=1000):\n",
    "    \"\"\"Evaluation d'une politique parametrée par le génotype\n",
    "\n",
    "    Evaluation d'une politique parametrée par le génotype\n",
    "    :param genotype: le paramètre de politique à évaluer\n",
    "    :param nbeval: le nombre de répétitions de l'évaluation à réaliser (une évaluation commençant à une position aléatoire)\n",
    "    :param render: affichage du pendule\n",
    "    :param nbstep: durée maximale d'une évaluation\n",
    "    \"\"\"\n",
    "    ## à completer\n",
    "\n",
    "\n",
    "    # ATTENTION: si le pendule tombe (done), vous pouvez interrompre l'évaluation pour accélérer les calculs, \n",
    "    # mais il faut compléter le calcul d'erreur pour ne pas favoriser ceux qui tombent rapidement...\n",
    "    \n",
    "    # La politique sera être créée avec l'instruction suivante:\n",
    "    # nn=nn.SimpleNeuralControllerNumpy(4,1,2,5).\n",
    "    # Vous utiliserez la fonction set_parameters pour positionner ses paramètres à partir du génotype \n",
    "    # et predict pour calculer l'action suggérée par la politique\n",
    "\n",
    "    # Le pendule a comme action 0 ou 1 qui correspondra à une force maximale dans un sens ou dans l'autre.\n",
    "    # L'action sera 0 pour une valeur de sortie négative du réseau de neurones et 1 sinon.\n",
    "\n",
    "    \n",
    "    total_x=0\n",
    "    total_theta=0\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "    return (total_x, total_theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cartpole_ea.py\n",
    "\n",
    "\n",
    "weights=(-1.0,)\n",
    "\n",
    "from deap import creator, base\n",
    "from ea_elitist import set_creator,ea_elitist\n",
    "\n",
    "set_creator(creator)\n",
    "if (hasattr(creator, \"MaFitness\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.MaFitness\n",
    "creator.create(\"MaFitness\", base.Fitness, weights=(weights))\n",
    "\n",
    "if (hasattr(creator, \"Individual\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.Individual\n",
    "creator.create(\"Individual\", list, fitness=creator.MaFitness)\n",
    "\n",
    "import nn\n",
    "import cartpole\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    name=\"elitist_cartpole\"\n",
    "    d=datetime.datetime.today()\n",
    "    dir=d.strftime(name+\"_%Y_%m_%d-%H:%M:%S\")\n",
    "    os.mkdir(dir)\n",
    "    nn=nn.SimpleNeuralControllerNumpy(4,1,2,5)\n",
    "    IND_SIZE=len(nn.get_parameters())\n",
    "\n",
    "    print(\"Results in \"+dir)\n",
    "\n",
    "    # à compléter pour faire appel à un algorithme évolutionniste mono-objectif sur le cartpole.\n",
    "    # Il est suggéré de sauvegarder le ou les logbook et hof dans le répertoire 'dir'\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de la question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cartpole_nsga2.py\n",
    "\n",
    "\n",
    "weights=(-1.0,-1.0)\n",
    "\n",
    "from deap import creator, base\n",
    "from nsga2 import set_creator,nsga2\n",
    "\n",
    "set_creator(creator)\n",
    "if (hasattr(creator, \"MaFitness\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.MaFitness\n",
    "creator.create(\"MaFitness\", base.Fitness, weights=(weights))\n",
    "\n",
    "if (hasattr(creator, \"Individual\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.Individual\n",
    "creator.create(\"Individual\", list, fitness=creator.MaFitness)\n",
    "\n",
    "import nn\n",
    "import cartpole\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    name=\"nsga2_cartpole\"\n",
    "    d=datetime.datetime.today()\n",
    "    dir=d.strftime(name+\"_%Y_%m_%d-%H:%M:%S\")\n",
    "    os.mkdir(dir)\n",
    "    nn=nn.SimpleNeuralControllerNumpy(4,1,2,5)\n",
    "    IND_SIZE=len(nn.get_parameters())\n",
    "\n",
    "    print(\"Results in \"+dir)\n",
    "\n",
    "    #<ANSWER>\n",
    "\n",
    "\n",
    "    #</ANSWER>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
